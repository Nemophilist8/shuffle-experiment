=== Dispatcher: Routing to task [tpch] ===
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/12/04 10:05:50 INFO SparkContext: Running Spark version 1.6.3
25/12/04 10:05:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/04 10:05:51 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
25/12/04 10:05:51 WARN Utils: Your hostname, hygon7490 resolves to a loopback address: 127.0.0.1; using 49.52.27.65 instead (on interface ens2f1np1)
25/12/04 10:05:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/12/04 10:05:51 INFO SecurityManager: Changing view acls to: djk
25/12/04 10:05:51 INFO SecurityManager: Changing modify acls to: djk
25/12/04 10:05:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(djk); users with modify permissions: Set(djk)
25/12/04 10:05:51 INFO Utils: Successfully started service 'sparkDriver' on port 36943.
25/12/04 10:05:51 INFO Slf4jLogger: Slf4jLogger started
25/12/04 10:05:51 INFO Remoting: Starting remoting
25/12/04 10:05:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@49.52.27.65:44479]
25/12/04 10:05:51 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 44479.
25/12/04 10:05:51 INFO SparkEnv: Registering MapOutputTracker
25/12/04 10:05:51 INFO SparkEnv: Registering BlockManagerMaster
25/12/04 10:05:51 INFO DiskBlockManager: Created local directory at /tmp/spark/work/blockmgr-c9c19fc5-7247-4ac4-88ca-bf4958993690
25/12/04 10:05:51 INFO MemoryStore: MemoryStore started with capacity 143.3 MB
25/12/04 10:05:51 INFO SparkEnv: Registering OutputCommitCoordinator
25/12/04 10:05:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/12/04 10:05:52 INFO SparkUI: Started SparkUI at http://49.52.27.65:4040
25/12/04 10:05:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark/work/spark-1e8f8355-8005-47ba-bcca-9ec8b1a4629b/httpd-9e9677aa-96ac-4cbe-94f6-e71d157b6fe9
25/12/04 10:05:52 INFO HttpServer: Starting HTTP Server
25/12/04 10:05:52 INFO Utils: Successfully started service 'HTTP file server' on port 43573.
25/12/04 10:05:52 INFO SparkContext: Added JAR file:/home/djk/Documents/shuffle-experiment/target/scala-2.10/spark-shuffle-experiment-1.0.0.jar at http://49.52.27.65:43573/jars/spark-shuffle-experiment-1.0.0.jar with timestamp 1764842752387
25/12/04 10:05:52 INFO AppClient$ClientEndpoint: Connecting to master spark://49.52.27.113:7077...
25/12/04 10:06:02 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20251204050552-0114
25/12/04 10:06:02 INFO AppClient$ClientEndpoint: Executor added: app-20251204050552-0114/0 on worker-20251203224515-49.52.27.60-35123 (49.52.27.60:35123) with 2 cores
25/12/04 10:06:02 INFO SparkDeploySchedulerBackend: Granted executor ID app-20251204050552-0114/0 on hostPort 49.52.27.60:35123 with 2 cores, 1024.0 MB RAM
25/12/04 10:06:02 INFO AppClient$ClientEndpoint: Executor added: app-20251204050552-0114/1 on worker-20251203144508-49.52.27.65-34725 (49.52.27.65:34725) with 2 cores
25/12/04 10:06:02 INFO SparkDeploySchedulerBackend: Granted executor ID app-20251204050552-0114/1 on hostPort 49.52.27.65:34725 with 2 cores, 1024.0 MB RAM
25/12/04 10:06:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39819.
25/12/04 10:06:02 INFO NettyBlockTransferService: Server created on 39819
25/12/04 10:06:02 INFO BlockManagerMaster: Trying to register BlockManager
25/12/04 10:06:02 INFO BlockManagerMasterEndpoint: Registering block manager 49.52.27.65:39819 with 143.3 MB RAM, BlockManagerId(driver, 49.52.27.65, 39819)
25/12/04 10:06:02 INFO BlockManagerMaster: Registered BlockManager
25/12/04 10:06:02 INFO AppClient$ClientEndpoint: Executor updated: app-20251204050552-0114/1 is now RUNNING
25/12/04 10:06:02 INFO AppClient$ClientEndpoint: Executor updated: app-20251204050552-0114/0 is now RUNNING
25/12/04 10:06:12 ERROR SparkContext: Error initializing SparkContext.
java.io.FileNotFoundException: File file:/home/djk/Documents/shuffle-experiment/logs/shuffle_file_test_20251204_100526/events_uniform_medium does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:747)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:524)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:409)
	at org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:100)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:549)
	at edu.ecnu.TPCHTest$.run(TPCHTest.scala:42)
	at edu.ecnu.MainEntry$.main(MainEntry.scala:29)
	at edu.ecnu.MainEntry.main(MainEntry.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
25/12/04 10:06:12 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (49.52.27.65:56332) with ID 1
25/12/04 10:06:12 INFO SparkUI: Stopped Spark web UI at http://49.52.27.65:4040
25/12/04 10:06:12 INFO SparkDeploySchedulerBackend: Shutting down all executors
25/12/04 10:06:12 INFO SparkDeploySchedulerBackend: Asking each executor to shut down
25/12/04 10:06:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/12/04 10:06:12 INFO MemoryStore: MemoryStore cleared
25/12/04 10:06:12 INFO BlockManager: BlockManager stopped
25/12/04 10:06:12 INFO BlockManagerMaster: BlockManagerMaster stopped
25/12/04 10:06:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/12/04 10:06:13 INFO SparkContext: Successfully stopped SparkContext
Exception in thread "main" java.io.FileNotFoundException: File file:/home/djk/Documents/shuffle-experiment/logs/shuffle_file_test_20251204_100526/events_uniform_medium does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:747)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:524)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:409)
	at org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:100)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:549)
	at edu.ecnu.TPCHTest$.run(TPCHTest.scala:42)
	at edu.ecnu.MainEntry$.main(MainEntry.scala:29)
	at edu.ecnu.MainEntry.main(MainEntry.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
25/12/04 10:06:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
25/12/04 10:06:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
25/12/04 10:06:13 INFO ShutdownHookManager: Shutdown hook called
25/12/04 10:06:13 INFO ShutdownHookManager: Deleting directory /tmp/spark/work/spark-1e8f8355-8005-47ba-bcca-9ec8b1a4629b/httpd-9e9677aa-96ac-4cbe-94f6-e71d157b6fe9
25/12/04 10:06:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
25/12/04 10:06:13 INFO ShutdownHookManager: Deleting directory /tmp/spark/work/spark-1e8f8355-8005-47ba-bcca-9ec8b1a4629b
