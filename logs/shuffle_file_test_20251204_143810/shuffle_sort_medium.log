=== Dispatcher: Routing to task [file] ===
Running File Count Monitor with args: sort medium
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/12/04 14:38:13 INFO SparkContext: Running Spark version 1.6.3
25/12/04 14:38:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/04 14:38:13 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
25/12/04 14:38:13 WARN Utils: Your hostname, hygon7490 resolves to a loopback address: 127.0.0.1; using 49.52.27.65 instead (on interface ens2f1np1)
25/12/04 14:38:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/12/04 14:38:13 INFO SecurityManager: Changing view acls to: djk
25/12/04 14:38:13 INFO SecurityManager: Changing modify acls to: djk
25/12/04 14:38:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(djk); users with modify permissions: Set(djk)
25/12/04 14:38:14 INFO Utils: Successfully started service 'sparkDriver' on port 39311.
25/12/04 14:38:14 INFO Slf4jLogger: Slf4jLogger started
25/12/04 14:38:14 INFO Remoting: Starting remoting
25/12/04 14:38:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@49.52.27.65:40193]
25/12/04 14:38:14 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 40193.
25/12/04 14:38:14 INFO SparkEnv: Registering MapOutputTracker
25/12/04 14:38:14 INFO SparkEnv: Registering BlockManagerMaster
25/12/04 14:38:14 INFO DiskBlockManager: Created local directory at /tmp/spark/work/blockmgr-1fd5d9e8-75dd-4fb4-ae26-60f24404a1cb
25/12/04 14:38:14 INFO MemoryStore: MemoryStore started with capacity 143.3 MB
25/12/04 14:38:14 INFO SparkEnv: Registering OutputCommitCoordinator
25/12/04 14:38:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/12/04 14:38:14 INFO SparkUI: Started SparkUI at http://49.52.27.65:4040
25/12/04 14:38:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark/work/spark-e40de1da-1de4-465e-bc46-85d7daa30d2b/httpd-127fb988-ae79-4a19-a513-b88b7947ac1d
25/12/04 14:38:14 INFO HttpServer: Starting HTTP Server
25/12/04 14:38:14 INFO Utils: Successfully started service 'HTTP file server' on port 38991.
25/12/04 14:38:15 INFO SparkContext: Added JAR file:/home/djk/Documents/shuffle-experiment/target/scala-2.10/spark-shuffle-experiment-1.0.0.jar at http://49.52.27.65:38991/jars/spark-shuffle-experiment-1.0.0.jar with timestamp 1764859095039
25/12/04 14:38:15 INFO AppClient$ClientEndpoint: Connecting to master spark://49.52.27.113:7077...
25/12/04 14:38:24 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20251204093815-0166
25/12/04 14:38:24 INFO AppClient$ClientEndpoint: Executor added: app-20251204093815-0166/0 on worker-20251203224515-49.52.27.60-35123 (49.52.27.60:35123) with 2 cores
25/12/04 14:38:24 INFO SparkDeploySchedulerBackend: Granted executor ID app-20251204093815-0166/0 on hostPort 49.52.27.60:35123 with 2 cores, 4.0 GB RAM
25/12/04 14:38:24 INFO AppClient$ClientEndpoint: Executor added: app-20251204093815-0166/1 on worker-20251203144508-49.52.27.65-34725 (49.52.27.65:34725) with 2 cores
25/12/04 14:38:24 INFO SparkDeploySchedulerBackend: Granted executor ID app-20251204093815-0166/1 on hostPort 49.52.27.65:34725 with 2 cores, 4.0 GB RAM
25/12/04 14:38:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43161.
25/12/04 14:38:24 INFO NettyBlockTransferService: Server created on 43161
25/12/04 14:38:24 INFO BlockManagerMaster: Trying to register BlockManager
25/12/04 14:38:24 INFO AppClient$ClientEndpoint: Executor updated: app-20251204093815-0166/1 is now RUNNING
25/12/04 14:38:24 INFO BlockManagerMasterEndpoint: Registering block manager 49.52.27.65:43161 with 143.3 MB RAM, BlockManagerId(driver, 49.52.27.65, 43161)
25/12/04 14:38:24 INFO AppClient$ClientEndpoint: Executor updated: app-20251204093815-0166/0 is now RUNNING
25/12/04 14:38:24 INFO BlockManagerMaster: Registered BlockManager
25/12/04 14:38:35 INFO EventLoggingListener: Logging events to file:/tmp/spark-events/app-20251204093815-0166
25/12/04 14:38:35 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
=== Shuffle File Monitor 实验 ===
3. Spark版本: 1.6.3
默认shuffle分区数: 200
请求的Shuffle Manager: sort
当前 Shuffle Manager: sort
Spark 本地目录: /tmp/spark/work
监控将每秒检查一次 /tmp/spark/work 目录中的 shuffle_* 文件
测试数据集: medium
分区数: 100
>>> 正在进行数据预热 (Cache & Count)...
>>> 预热完成! 数据已驻留内存。耗时: 27603ms, 记录数: 5000000
>>> 现在开始正式 Shuffle 实验 (此时文件应该会立即产生)

=== 开始运行 sort 实验 ===
启动Shuffle文件监控，每秒检查一次...
[ShuffleMonitor 14:39:03] 文件数: 88, 总大小: 1KB (峰值: 88文件, 1KB)
[ShuffleMonitor 14:39:04] 文件数: 90, 总大小: 33.71MB (峰值: 90文件, 33.71MB)
[ShuffleMonitor 14:39:05] 文件数: 94, 总大小: 177.92MB (峰值: 94文件, 177.92MB)
[ShuffleMonitor 14:39:06] 文件数: 97, 总大小: 297.52MB (峰值: 97文件, 297.52MB)
[ShuffleMonitor 14:39:07] 文件数: 100, 总大小: 443.97MB (峰值: 100文件, 443.97MB)
[ShuffleMonitor 14:39:08] 文件数: 104, 总大小: 591.73MB (峰值: 104文件, 591.73MB)
[ShuffleMonitor 14:39:09] 文件数: 108, 总大小: 740.09MB (峰值: 108文件, 740.09MB)
[ShuffleMonitor 14:39:10] 文件数: 112, 总大小: 888.29MB (峰值: 112文件, 888.29MB)
[ShuffleMonitor 14:39:11] 文件数: 116, 总大小: 1.01GB (峰值: 116文件, 1.01GB)
[ShuffleMonitor 14:39:12] 文件数: 120, 总大小: 1.16GB (峰值: 120文件, 1.16GB)
[ShuffleMonitor 14:39:13] 文件数: 124, 总大小: 1.30GB (峰值: 124文件, 1.30GB)
[ShuffleMonitor 14:39:14] 文件数: 127, 总大小: 1.42GB (峰值: 127文件, 1.42GB)
[ShuffleMonitor 14:39:15] 文件数: 131, 总大小: 1.57GB (峰值: 131文件, 1.57GB)
[ShuffleMonitor 14:39:16] 文件数: 135, 总大小: 1.70GB (峰值: 135文件, 1.70GB)
[ShuffleMonitor 14:39:17] 文件数: 138, 总大小: 1.77GB (峰值: 138文件, 1.77GB)
[ShuffleMonitor 14:39:18] 文件数: 142, 总大小: 1.88GB (峰值: 142文件, 1.88GB)
[ShuffleMonitor 14:39:20] 文件数: 144, 总大小: 2.03GB (峰值: 144文件, 2.03GB)
[ShuffleMonitor 14:39:21] 文件数: 149, 总大小: 2.17GB (峰值: 149文件, 2.17GB)
[ShuffleMonitor 14:39:22] 文件数: 153, 总大小: 2.32GB (峰值: 153文件, 2.32GB)
[ShuffleMonitor 14:39:23] 文件数: 156, 总大小: 2.46GB (峰值: 156文件, 2.46GB)
[ShuffleMonitor 14:39:24] 文件数: 161, 总大小: 2.62GB (峰值: 161文件, 2.62GB)
[ShuffleMonitor 14:39:25] 文件数: 164, 总大小: 2.73GB (峰值: 164文件, 2.73GB)
[ShuffleMonitor 14:39:26] 文件数: 167, 总大小: 2.83GB (峰值: 167文件, 2.83GB)
[ShuffleMonitor 14:39:27] 文件数: 170, 总大小: 2.97GB (峰值: 170文件, 2.97GB)
[ShuffleMonitor 14:39:28] 文件数: 173, 总大小: 3.11GB (峰值: 173文件, 3.11GB)
[ShuffleMonitor 14:39:29] 文件数: 176, 总大小: 3.19GB (峰值: 176文件, 3.19GB)
[ShuffleMonitor 14:39:30] 文件数: 180, 总大小: 3.34GB (峰值: 180文件, 3.34GB)
[ShuffleMonitor 14:39:31] 文件数: 185, 总大小: 3.52GB (峰值: 185文件, 3.52GB)
[ShuffleMonitor 14:39:32] 文件数: 189, 总大小: 3.68GB (峰值: 189文件, 3.68GB)
[ShuffleMonitor 14:39:33] 文件数: 194, 总大小: 3.83GB (峰值: 194文件, 3.83GB)
[ShuffleMonitor 14:39:34] 文件数: 198, 总大小: 3.98GB (峰值: 198文件, 3.98GB)
[ShuffleMonitor 14:39:35] 文件数: 202, 总大小: 4.12GB (峰值: 202文件, 4.12GB)
[ShuffleMonitor 14:39:36] 文件数: 207, 总大小: 4.30GB (峰值: 207文件, 4.30GB)
[ShuffleMonitor 14:39:37] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:38] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:39] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:40] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:41] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:42] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:43] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:44] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:45] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:46] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:47] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:48] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:49] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:50] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:51] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:52] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:53] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:54] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:55] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:56] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:57] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:58] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:39:59] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:00] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:01] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:02] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:03] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:04] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:05] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:06] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:07] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:08] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:09] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:10] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:11] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:12] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:13] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:14] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:15] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:16] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:17] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:18] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:19] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:20] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:21] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:22] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:23] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:24] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:25] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:26] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:27] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:28] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:29] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:30] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:31] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:32] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:33] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:34] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:35] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:36] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:37] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:38] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:39] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:40] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:41] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:42] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
25/12/04 14:40:42 WARN TaskSetManager: Lost task 438.0 in stage 3.0 (TID 639, 49.52.27.60): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.Arrays.copyOfRange(Arrays.java:3664)
	at java.lang.String.<init>(String.java:207)
	at com.esotericsoftware.kryo.io.Input.readString(Input.java:448)
	at com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.read(DefaultSerializers.java:157)
	at com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.read(DefaultSerializers.java:146)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:228)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:171)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:201)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:198)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

25/12/04 14:40:42 WARN TaskSetManager: Lost task 439.0 in stage 3.0 (TID 640, 49.52.27.60): FetchFailed(BlockManagerId(0, 49.52.27.60, 38279), shuffleId=1, mapId=1, reduceId=439, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark/work/spark-8a7f7c7e-f3b8-4789-8bf7-16307955151b/executor-fd6e8b8e-863b-49e1-bae1-4cffeb7352d7/blockmgr-44e23522-c277-4e2e-84c1-de87c7d45a83/32/shuffle_1_1_0.index (No such file or directory)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:323)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:300)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.FileNotFoundException: /tmp/spark/work/spark-8a7f7c7e-f3b8-4789-8bf7-16307955151b/executor-fd6e8b8e-863b-49e1-bae1-4cffeb7352d7/blockmgr-44e23522-c277-4e2e-84c1-de87c7d45a83/32/shuffle_1_1_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:197)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:298)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:238)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:112)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:43)
	... 9 more

)
25/12/04 14:40:42 WARN TaskSetManager: Lost task 438.1 in stage 3.0 (TID 641, 49.52.27.60): FetchFailed(BlockManagerId(0, 49.52.27.60, 38279), shuffleId=1, mapId=1, reduceId=438, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark/work/spark-8a7f7c7e-f3b8-4789-8bf7-16307955151b/executor-fd6e8b8e-863b-49e1-bae1-4cffeb7352d7/blockmgr-44e23522-c277-4e2e-84c1-de87c7d45a83/32/shuffle_1_1_0.index (No such file or directory)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:323)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:300)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.FileNotFoundException: /tmp/spark/work/spark-8a7f7c7e-f3b8-4789-8bf7-16307955151b/executor-fd6e8b8e-863b-49e1-bae1-4cffeb7352d7/blockmgr-44e23522-c277-4e2e-84c1-de87c7d45a83/32/shuffle_1_1_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:197)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:298)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:238)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:112)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:43)
	... 9 more

)
[ShuffleMonitor 14:40:43] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
25/12/04 14:40:44 WARN TransportChannelHandler: Exception in connection from 49.52.27.60/49.52.27.60:34836
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:313)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:881)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:750)
25/12/04 14:40:44 ERROR TaskSchedulerImpl: Lost executor 0 on 49.52.27.60: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
25/12/04 14:40:44 WARN TaskSetManager: Lost task 437.0 in stage 3.0 (TID 638, 49.52.27.60): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
25/12/04 14:40:44 WARN TaskSetManager: Lost task 0.0 in stage 2.1 (TID 642, 49.52.27.60): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
[ShuffleMonitor 14:40:44] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:45] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:46] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:47] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:48] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:49] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:50] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:51] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:52] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:53] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:54] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:55] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:56] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:57] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:58] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:40:59] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
25/12/04 14:41:00 WARN TaskSetManager: Lost task 435.0 in stage 3.0 (TID 636, 49.52.27.65): FetchFailed(BlockManagerId(0, 49.52.27.60, 38279), shuffleId=1, mapId=53, reduceId=435, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /49.52.27.60:38279
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:323)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:300)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: Failed to connect to /49.52.27.60:38279
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:216)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:167)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:90)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
Caused by: java.net.ConnectException: Connection refused: /49.52.27.60:38279
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	... 1 more

)
25/12/04 14:41:00 WARN TaskSetManager: Lost task 436.0 in stage 3.0 (TID 637, 49.52.27.65): FetchFailed(BlockManagerId(0, 49.52.27.60, 38279), shuffleId=1, mapId=71, reduceId=436, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /49.52.27.60:38279
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:323)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:300)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: Failed to connect to /49.52.27.60:38279
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:216)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:167)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:90)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
Caused by: java.net.ConnectException: Connection refused: /49.52.27.60:38279
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	... 1 more

)
[ShuffleMonitor 14:41:00] 文件数: 210, 总大小: 4.41GB (峰值: 210文件, 4.41GB)
[ShuffleMonitor 14:41:01] 文件数: 212, 总大小: 4.47GB (峰值: 212文件, 4.47GB)
[ShuffleMonitor 14:41:02] 文件数: 216, 总大小: 4.59GB (峰值: 216文件, 4.59GB)
[ShuffleMonitor 14:41:03] 文件数: 220, 总大小: 4.73GB (峰值: 220文件, 4.73GB)
[ShuffleMonitor 14:41:04] 文件数: 223, 总大小: 4.87GB (峰值: 223文件, 4.87GB)
[ShuffleMonitor 14:41:05] 文件数: 227, 总大小: 5.02GB (峰值: 227文件, 5.02GB)
[ShuffleMonitor 14:41:06] 文件数: 231, 总大小: 5.15GB (峰值: 231文件, 5.15GB)
[ShuffleMonitor 14:41:07] 文件数: 235, 总大小: 5.29GB (峰值: 235文件, 5.29GB)
[ShuffleMonitor 14:41:08] 文件数: 239, 总大小: 5.46GB (峰值: 239文件, 5.46GB)
[ShuffleMonitor 14:41:09] 文件数: 243, 总大小: 5.62GB (峰值: 243文件, 5.62GB)
[ShuffleMonitor 14:41:10] 文件数: 247, 总大小: 5.78GB (峰值: 247文件, 5.78GB)
[ShuffleMonitor 14:41:11] 文件数: 253, 总大小: 5.95GB (峰值: 253文件, 5.95GB)
[ShuffleMonitor 14:41:12] 文件数: 257, 总大小: 6.10GB (峰值: 257文件, 6.10GB)
[ShuffleMonitor 14:41:13] 文件数: 261, 总大小: 6.25GB (峰值: 261文件, 6.25GB)
[ShuffleMonitor 14:41:14] 文件数: 265, 总大小: 6.42GB (峰值: 265文件, 6.42GB)
[ShuffleMonitor 14:41:15] 文件数: 270, 总大小: 6.58GB (峰值: 270文件, 6.58GB)
[ShuffleMonitor 14:41:16] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:17] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:18] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:19] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:20] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:21] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:22] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:23] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:24] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:25] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:26] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:27] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:28] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:29] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:31] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:32] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:33] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:34] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:35] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:36] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:37] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:38] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:39] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:40] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:41] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:42] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:43] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:44] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:45] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:46] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:47] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:48] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:49] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:50] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:51] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:52] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:53] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:54] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:55] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:56] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:57] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:58] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:41:59] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:42:00] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:42:01] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:42:02] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
[ShuffleMonitor 14:42:03] 文件数: 272, 总大小: 6.66GB (峰值: 272文件, 6.66GB)
